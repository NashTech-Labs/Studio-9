orion-service {
  name = "orion-api"
  version = "v1"
}

# Options: OFF, ERROR, WARNING, INFO, DEBUG
akka-loglevel = "INFO"
akka-loglevel = ${?AKKA_LOGLEVEL}

zookeeper-url = "127.0.0.1:2181"
zookeeper-url = ${?ZOOKEEPER_URL}

canonical-hostname = "127.0.0.1"
canonical-hostname = ${?LIBPROCESS_IP}

canonical-port = 2552
canonical-port = ${?PORT_2552}

bind-port = 2552
bind-port = ${?BIND_PORT}

rabbit-hosts = "0.0.0.0"
rabbit-hosts = ${?RABBIT_HOSTS}

rabbit-username = "guest"
rabbit-username = ${?RABBIT_USERNAME}

rabbit-password = "guest"
rabbit-password = ${?RABBIT_PASSWORD}

search-user-name = "search-user"
search-user-name = ${?HTTP_SEARCH_USER_NAME}

search-user-password = "search-password"
search-user-password = ${?HTTP_SEARCH_USER_PASSWORD}

akka {
  loglevel = ${akka-loglevel}
  log-dead-letters = 10
  log-dead-letters-during-shutdown = on
  jvm-exit-on-fatal-error = off
  log-config-on-start = off

  loggers = ["akka.event.slf4j.Slf4jLogger"]
  logging-filter = "akka.event.slf4j.Slf4jLoggingFilter"

  actor {
    # which serializers are available under which key
    serializers {
      java = "akka.serialization.JavaSerializer"
      job-message = "orion.common.serialization.JobMessagePlayJsonSerializer"
    }

    # which interfaces / traits / classes should be handled by which serializer
    serialization-bindings {
      "java.io.Serializable" = java
      "cortex.api.job.message.JobMessage" = job-message
    }

    provider = "cluster"

    debug {
      receive = on
      autoreceive = on
      lifecycle = on
      fsm = on
      event-stream = off
    }

    info {
      receive = off
      autoreceive = off
      lifecycle = off
      event-stream = off
    }

    deployment {
      /job-dispatcher {
        router = round-robin-pool
        nr-of-instances = 2
      }
      /job-resources-cleaner {
        router = round-robin-pool
        nr-of-instances = 2
      }
    }
  }

  remote {
    log-remote-lifecycle-events = off

    netty.tcp {
      hostname = ${canonical-hostname}
      port = ${canonical-port}
      bind-hostname = "127.0.0.1"
      bind-port = ${bind-port}
    }
  }

  http {
    server {
      server-header = ${orion-service.name}/${orion-service.version}
      idle-timeout = 60 s
      request-timeout = 120 s
      max-connections = 1024
    }

    client {
      connecting-timeout = 120 s
    }

    host-connection-pool {
      max-connections = 1024
      max-retries = 3
      max-open-requests = 16384
    }
  }

  cluster {
    # auto downing is NOT safe for production deployments.
    # you may want to use it during development, read more about it in the docs.
    #
    auto-down-unreachable-after = 10s

    seed.zookeeper {
      url = ${zookeeper-url}
      path = "/akka/cluster/seed"
      host_env_var = ${canonical-hostname}
      port_env_var = ${canonical-port}
    }
  }

  persistence {
    journal {
      plugin = "akka-contrib-mongodb-persistence-journal"
      auto-start-journals = ["akka-contrib-mongodb-persistence-journal"]
    }
    snapshot-store {
      plugin = "akka-contrib-mongodb-persistence-snapshot"
      auto-start-snapshot-stores = ["akka-contrib-mongodb-persistence-snapshot"]
    }
  }

  extensions = [akka.persistence.Persistence]

  contrib.persistence.mongodb.mongo {
    mongouri = "mongodb://user:password@192.168.0.1:27017,192.168.0.2:27017/orion-akka-persistence"
    mongouri = ${?AKKA_PERSISTENCE_MONGODB_URI}
    journal-collection = "persistentJournal"
    journal-index = "journal_index"
    snaps-collection = "persistentSnapshots"
    snaps-index = "snaphots_index"
    # Options:
    # ReplicaAcknowledged - requires a replica to acknowledge the write, this confirms that at least two servers have seen the write
    # Journaled - requires that the change be journaled on the server that was written to. Other replicas may not see this write on a network partition
    # Acknowledged - also known as "Safe", requires that the MongoDB server acknowledges the write. This does not require that the change be persistent anywhere but memory.
    journal-write-concern = "Journaled"
    journal-write-concern = ${?AKKA_PERSISTENCE_MONGODB_WRITE_CONCERN}
  }
}

http {
  interface = "0.0.0.0"
  port = 9000
  search-user-name = ${search-user-name}
  search-user-password = ${search-user-password}
}

op-rabbit {
  topic-exchange-name = "ml_job.gateway"
  channel-dispatcher = "op-rabbit.default-channel-dispatcher"
  default-channel-dispatcher {
    # Dispatcher is the name of the event-based dispatcher
    type = Dispatcher

    # What kind of ExecutionService to use
    executor = "fork-join-executor"

    # Configuration for the fork join pool
    fork-join-executor {
      # Min number of threads to cap factor-based parallelism number to
      parallelism-min = 2

      # Parallelism (threads) ... ceil(available processors * factor)
      parallelism-factor = 2.0

      # Max number of threads to cap factor-based parallelism number to
      parallelism-max = 4
    }
    # Throughput defines the maximum number of messages to be
    # processed per actor before the thread jumps to the next actor.
    # Set to 1 for as fair as possible.
    throughput = 10
  }
  connection {
    virtual-host = "/"
    hosts = [${rabbit-hosts}]
    username = ${rabbit-username}
    password = ${rabbit-password}
    port = 5672
    ssl = false
    connection-timeout = 3s
  }
}

marathon-client {
  marathon-endpoint = "http://10.15.163.100:8080"
  marathon-endpoint = ${?MARATHON_CLIENT_MARATHON_ENDPOINT}
}

job-supervisor {
  job-master-start-timeout = 5 minutes
  job-master-start-timeout = ${?JOB_MASTER_START_TIMEOUT}
  job-master-heartbeat-timeout = 5 minutes
  job-master-heartbeat-timeout = ${?JOB_MASTER_HEARTBEAT_TIMEOUT}
  message-publishing-timeout = 30 seconds
  message-publishing-timeout = ${?JOB_SUPERVISOR_MESSAGE_PUBLISHING_TIMEOUT}
  message-publishing-retries = 20
  message-publishing-retries = ${?JOB_SUPERVISOR_MESSAGE_PUBLISHING_RETRIES}
}

job-master {
  docker-image = "deepcortex/cortex-job-master:0.9.0-1-g8d4ca16"
  docker-image = ${?JOB_MASTER_DOCKER_IMAGE}

  force-docker-pull = false

  s3-access-key = ""
  s3-access-key = ${?JOB_MASTER_S3_ACCESS_KEY}

  s3-secret-key = ""
  s3-secret-key = ${?JOB_MASTER_S3_SECRET_KEY}

  s3-region = "s3-region"
  s3-region = ${?JOB_MASTER_S3_REGION}

  s3-bucket = "s3-bucket"
  s3-bucket = ${?JOB_MASTER_S3_BUCKET}

  s3-tables-dir = "tables"
  s3-tables-dir = ${?JOB_MASTER_S3_TABLES_DIR}

  dremio-url = "http://dremio"
  dremio-url = ${?JOB_MASTER_DREMIO_URL}

  dremio-username = "deepcortex"
  dremio-username = ${?JOB_MASTER_DREMIO_USERNAME}

  dremio-password = ""
  dremio-password = ${?JOB_MASTER_DREMIO_PASSWORD}

  dremio-source = "s3-source"
  dremio-source = ${?JOB_MASTER_DREMIO_SOURCE}

  dremio-namespace = "namespace"
  dremio-namespace = ${?JOB_MASTER_DREMIO_NAMESPACE}

  redshift-host = "redshift.amazonaws.com"
  redshift-host = ${?JOB_MASTER_REDSHIFT_HOST}

  redshift-port = "5439"
  redshift-port = ${?JOB_MASTER_REDSHIFT_PORT}

  redshift-database = "test"
  redshift-database = ${?JOB_MASTER_REDSHIFT_DATABASE}

  redshift-username = "deepcortex"
  redshift-username = ${?JOB_MASTER_REDSHIFT_USERNAME}

  redshift-password = ""
  redshift-password = ${?JOB_MASTER_REDSHIFT_PASSWORD}

  redshift-s3-iam-role = ""
  redshift-s3-iam-role = ${?JOB_MASTER_REDSHIFT_S3_IAM_ROLE}

  baile-url = "http://baile/v2.0"
  baile-url = ${?JOB_MASTER_BAILE_URL}

  sql-server-url = "http://sql-server/v1.0"
  sql-server-url = ${?JOB_MASTER_SQL_SERVER_URL}

  cortex-task-version = ""
  cortex-task-version = ${?JOB_MASTER_CORTEX_TASK_VERSION}

  # used to specify a different docker repository for private deployments
  cortex-task-registry-prefix = ""
  cortex-task-registry-prefix = ${?JOB_MASTER_CORTEX_TASK_REGISTRY_PREFIX}


  app-environment-variables = [
    { name = "RABBIT_HOSTS", value = ${rabbit-hosts} },
    { name = "RABBIT_USERNAME", value = ${rabbit-username} },
    { name = "RABBIT_PASSWORD", value = ${rabbit-password} },
    { name = "S3_ACCESS_KEY", value = ${job-master.s3-access-key} },
    { name = "S3_SECRET_KEY", value = ${job-master.s3-secret-key} },
    { name = "S3_REGION", value = ${job-master.s3-region} },
    { name = "S3_BUCKET", value = ${job-master.s3-bucket} },
    { name = "S3_TABLES_DIR", value = ${job-master.s3-tables-dir} },
    { name = "DREMIO_URL", value = ${job-master.dremio-url} },
    { name = "DREMIO_USERNAME", value = ${job-master.dremio-username} },
    { name = "DREMIO_PASSWORD", value = ${job-master.dremio-password} },
    { name = "DREMIO_SOURCE", value = ${job-master.dremio-source} },
    { name = "DREMIO_NAMESPACE", value = ${job-master.dremio-namespace} },
    { name = "REDSHIFT_HOST", value = ${job-master.redshift-host} },
    { name = "REDSHIFT_PORT", value = ${job-master.redshift-port} },
    { name = "REDSHIFT_DATABASE", value = ${job-master.redshift-database} },
    { name = "REDSHIFT_USERNAME", value = ${job-master.redshift-username} },
    { name = "REDSHIFT_PASSWORD", value = ${job-master.redshift-password} },
    { name = "REDSHIFT_S3_IAM_ROLE", value = ${job-master.redshift-s3-iam-role} },
    { name = "BAILE_URL", value = ${job-master.baile-url} },
    { name = "SQL_SERVER_URL", value = ${job-master.sql-server-url} },
    { name = "CORTEX_TASK_VERSION", value = ${job-master.cortex-task-version} },
    { name = "CORTEX_TASK_REGISTRY_PREFIX", value = ${job-master.cortex-task-registry-prefix} }
  ]

  mesos-master-address = "master.mesos:5050"
  mesos-master-address = ${?JOB_MASTER_MESOS_MASTER_ADDRESS}

  cpus = 1
  cpus = ${?JOB_MASTER_CPUS}

  memory = 1024
  memory = ${?JOB_MASTER_MEMORY}

  instances = 1
  instances = ${?JOB_MASTER_INSTANCES}

  //percent of "memory parameter" which will be used as Xmx param for jvm. should be integer in range [1; 100]
  jvm-heapsize-factor = 65
  jvm-heapsize-factor = ${?JOB_MASTER_JVM_HEAPSIZE_FACTOR}
}
